services:
  # Command server (submission) - starts first and stays running
  submission:
    build:
      context: ${SUBMISSION_FOLDER:-./scenarios/numberguess_game}
      dockerfile: Dockerfile
    container_name: submission_server
    volumes:
      - shared_pipes:/shared
    # Keep the container running and restart if it fails
    restart: unless-stopped
    # Add some debug output
    environment:
      - PYTHONUNBUFFERED=1
    # Health check to ensure the server is ready
    healthcheck:
      test: ["CMD", "test", "-p", "/shared/command_pipe", "-a", "-p", "/shared/response_pipe"]
      interval: 2s
      timeout: 1s
      retries: 30
      start_period: 5s
    networks:
      - isolated_network

  # Agent controller - runs the test commands and then exits
  agent:
    build:
      context: .
      dockerfile: agent/Dockerfile
    container_name: agent_controller
    volumes:
      - shared_pipes:/shared
    depends_on:
      submission:
        condition: service_healthy
    # Agent should exit after completing its work
    restart: "no"
    environment:
      - PYTHONUNBUFFERED=1
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      # Vertex AI configuration
      - GCP_PROJECT_ID=${GCP_PROJECT_ID:-}
      - GCP_LOCATION=${GCP_LOCATION:-us-central1}
      - USE_VERTEX_AI=${USE_VERTEX_AI:-false}
      - GOOGLE_APPLICATION_CREDENTIALS=${GOOGLE_APPLICATION_CREDENTIALS:-}
      # Legacy OpenAI config (unused)
      - OPENAI_VALIDATE_MODEL=${OPENAI_VALIDATE_MODEL:-gpt-5}
      - OPENAI_EVAL_MODEL=${OPENAI_EVAL_MODEL:-gpt-5}
      - OPENAI_FALLBACK_MODEL=${OPENAI_FALLBACK_MODEL:-gpt-5}
      - UNIFIED_MODEL=${UNIFIED_MODEL:-unknown}
      - UNIFIED_REASONING=${UNIFIED_REASONING:-unknown}
      - UNIFIED_IMPLEMENTATION=${UNIFIED_IMPLEMENTATION:-Enhanced Palisade}
      - UNIFIED_EXPERIMENT_ID=${UNIFIED_EXPERIMENT_ID:-unknown}
      - UNIFIED_MAX_STEPS=${UNIFIED_MAX_STEPS:-30}
      - UNIFIED_SCENARIO=${UNIFIED_SCENARIO:-unknown}
      # Datadog LLM Observability
      - DD_API_KEY=${DD_API_KEY:-}
      - DD_SITE=${DD_SITE:-datadoghq.com}
      - DD_SERVICE=${DD_SERVICE:-ai-safety-evals}
      - DD_ENV=${DD_ENV:-development}
      - DD_LLMOBS_ENABLED=1
      - DD_LLMOBS_ML_APP=ai-safety-evals
      - DD_TRACE_AGENT_URL=http://host.docker.internal:8126
    # Agent has access to both networks for communication
    networks:
      - default
      - isolated_network

volumes:
  # Shared volume for named pipes communication
  shared_pipes:
    driver: local

networks:
  # Internal network with no external internet access
  isolated_network:
    driver: bridge
    internal: true
